import type OpenAI from 'openai';
import type {
  ChatCompletionMessageParam,
  ChatCompletionTool,
  ChatCompletionToolMessageParam,
} from 'openai/resources/chat/completions';
import {openai} from './openai-client.js';

export type ToolResult = Omit<ChatCompletionToolMessageParam, 'role'>;

export interface SessionOptions {
  /** Defaults to OPENAI_MODEL env var or 'gpt-4'. */
  model?: string;
  systemPrompt?: string;
  tools?: ChatCompletionTool[];
}

/**
 * Manages a conversation session with an OpenAI-compatible API.
 *
 * @example Basic usage
 * ```typescript
 * const session = new Session({
 *   systemPrompt: 'You are a helpful assistant.',
 * });
 *
 * const response = await session.chat('Hello!');
 * console.log(response.choices[0].message.content);
 * ```
 *
 * @example Using tools
 * ```typescript
 * // 1. Define your tool implementations
 * const toolImplementations: Record<string, (args: unknown) => Promise<string>> = {
 *   get_weather: async (args) => {
 *     const { location } = args as { location: string };
 *     // Your implementation here
 *     return JSON.stringify({ temp: 20, condition: 'sunny' });
 *   },
 * };
 *
 * // 2. Create session with tool definitions
 * const session = new Session({
 *   tools: [
 *     {
 *       type: 'function',
 *       function: {
 *         name: 'get_weather',
 *         description: 'Get current weather for a location',
 *         parameters: {
 *           type: 'object',
 *           properties: {
 *             location: { type: 'string' },
 *           },
 *           required: ['location'],
 *         },
 *       },
 *     },
 *   ],
 * });
 *
 * // 3. Chat and handle tool calls
 * let response = await session.chat('What is the weather in Tokyo?');
 *
 * while (Session.requiresToolCall(response)) {
 *   const toolCalls = response.choices[0].message.tool_calls!;
 *   const results: ToolResult[] = [];
 *
 *   for (const toolCall of toolCalls) {
 *     const fn = toolImplementations[toolCall.function.name];
 *     const args = JSON.parse(toolCall.function.arguments);
 *     const output = await fn(args);
 *     results.push({ tool_call_id: toolCall.id, content: output });
 *   }
 *
 *   response = await session.submitToolResults(results);
 * }
 *
 * console.log(response.choices[0].message.content);
 * ```
 */
export class Session {
  private messages: ChatCompletionMessageParam[] = [];
  private model: string;
  private tools: ChatCompletionTool[];

  constructor(options: SessionOptions = {}) {
    this.model = options.model ?? process.env['OPENAI_MODEL'] ?? 'gpt-4';
    this.tools = options.tools ?? [];

    if (options.systemPrompt) {
      this.messages.push({role: 'system', content: options.systemPrompt});
    }
  }

  /**
   * Checks if a response requires tool calls to be executed.
   *
   * @example
   * ```typescript
   * const response = await session.chat('What is the weather?');
   * if (Session.requiresToolCall(response)) {
   *   const toolCalls = response.choices[0].message.tool_calls!;
   *   const results: ToolResult[] = toolCalls.map((call) => ({
   *     tool_call_id: call.id,
   *     content: executeMyTool(call.function.name, call.function.arguments),
   *   }));
   *   await session.submitToolResults(results);
   * }
   * ```
   */
  static requiresToolCall(
    response: OpenAI.Chat.Completions.ChatCompletion,
  ): boolean {
    return response.choices[0]?.finish_reason === 'tool_calls';
  }

  addUserMessage(content: string): void {
    this.messages.push({role: 'user', content});
  }

  addAssistantMessage(content: string): void {
    this.messages.push({role: 'assistant', content});
  }

  async chat(
    userMessage: string,
  ): Promise<OpenAI.Chat.Completions.ChatCompletion> {
    this.addUserMessage(userMessage);

    const response = await openai.chat.completions.create({
      model: this.model,
      messages: this.messages,
      ...(this.tools.length > 0 && {tools: this.tools}),
    });

    const message = response.choices[0]?.message;
    if (message) {
      this.messages.push(message);
    }

    return response;
  }

  async submitToolResults(
    results: ToolResult[],
  ): Promise<OpenAI.Chat.Completions.ChatCompletion> {
    const toolMessages: ChatCompletionToolMessageParam[] = results.map(
      (result) => ({
        role: 'tool' as const,
        ...result,
      }),
    );

    this.messages.push(...toolMessages);

    const response = await openai.chat.completions.create({
      model: this.model,
      messages: this.messages,
      ...(this.tools.length > 0 && {tools: this.tools}),
    });

    const message = response.choices[0]?.message;
    if (message) {
      this.messages.push(message);
    }

    return response;
  }

  getMessages(): ChatCompletionMessageParam[] {
    return [...this.messages];
  }

  clearMessages(): void {
    this.messages = [];
  }
}
